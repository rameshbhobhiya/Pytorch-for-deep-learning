{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b908bc7d",
   "metadata": {},
   "source": [
    "![alt text](pytorch_seo.avif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14929c0e",
   "metadata": {},
   "source": [
    "## PyTorch for Deep Learning: A Comprehensive Lecture "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e8785",
   "metadata": {},
   "source": [
    "### What is PyTorch?\n",
    "\n",
    " PyTorch is an open-source machine learning library primarily used for applications like computer vision and natural language processing. It's developed by Facebook's AI Research lab (FAIR) and is known for its:\n",
    "\n",
    "1. Pythonic Nature: It feels very natural to Python developers, integrating seamlessly with the Python ecosystem.\n",
    "\n",
    "2. Dynamic Computation Graph: Unlike some other frameworks that use static graphs, PyTorch uses a dynamic computation graph. This means the graph is built on the fly as operations are performed, offering incredible flexibility for debugging and handling variable-length inputs.\n",
    "\n",
    "3. Ease of Use: It's often praised for its simplicity and intuitive API, making it easier to learn and experiment with.\n",
    "\n",
    "4. Strong GPU Acceleration: It leverages the power of GPUs for efficient computation, crucial for training large deep learning models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7542bcc",
   "metadata": {},
   "source": [
    "![alt text](content-anchor-GPU-diagram.png)![alt text](Parallel-computing-1-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d4324",
   "metadata": {},
   "source": [
    "## Any exmaple of Parallel Computing ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6cba68",
   "metadata": {},
   "source": [
    "### Why Choose PyTorch?\n",
    "\n",
    "\n",
    "- Flexibility and Debugging: The dynamic graph allows for easier debugging using standard Python debugging tools. You can inspect values at any point in your network.\n",
    "\n",
    "- Research-Friendly: Its flexibility makes it a favorite among researchers for rapid prototyping and experimentation with novel architectures.\n",
    "\n",
    "- Growing Community and Ecosystem: PyTorch has a vibrant and rapidly growing community, with extensive documentation, tutorials, and pre-trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c59a07",
   "metadata": {},
   "source": [
    "## Core Concepts of PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e1e9f",
   "metadata": {},
   "source": [
    "### Core Concepts of PyTorch\n",
    "\n",
    "PyTorch operates on Tensors. Think of a Tensor as a multi-dimensional array, very similar to NumPy arrays, but with the added capability to run on GPUs and track gradients for automatic differentiation.\n",
    "\n",
    "Scalars: 0-D Tensor (single number)\n",
    "\n",
    "Vectors: 1-D Tensor (list of numbers)\n",
    "\n",
    "Matrices: 2-D Tensor (table of numbers)\n",
    "\n",
    "Higher-dimensional Tensors: For images (height x width x channels), video (frames x height x width x channels), etc.\n",
    "\n",
    "### Key Tensor Operations:\n",
    "You can perform various operations on Tensors, just like NumPy arrays:\n",
    "\n",
    "Arithmetic operations (+, -, *, /)\n",
    "\n",
    "Matrix multiplication (torch.matmul())\n",
    "\n",
    "Reshaping (.view(), .reshape())\n",
    "\n",
    "Indexing and Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059eec24",
   "metadata": {},
   "source": [
    "### Tensor Creation and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4051c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "NumPy Array Type: <class 'numpy.ndarray'>\n",
      "NumPy Array Shape: (2, 2)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a NumPy array\n",
    "np_array = np.array([[[1, 2], [3, 4]]])\n",
    "print(\"NumPy Array:\\n\", np_array)\n",
    "print(\"NumPy Array Type:\", type(np_array))\n",
    "print(\"NumPy Array Shape:\", np_array.shape)\n",
    "\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd0e30",
   "metadata": {},
   "source": [
    "## Importing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b64b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5233f9",
   "metadata": {},
   "source": [
    "## Introduction to tensors \n",
    "\n",
    "Tensors are the fundamental building block of machine learning.\n",
    "\n",
    "- We represent data in a numerical way.\n",
    "\n",
    "For example, you could represent an image as a tensor with shape `[3, 224, 224]` which would mean `[colour_channels, height, width]`, as in the image has `3` colour channels (red, green, blue), a height of `224` pixels and a width of `224` pixels.\n",
    "\n",
    "\n",
    "\n",
    "![alt text](00-tensor-shape-example-of-image.png)\n",
    "\n",
    "The tensor would have three dimensions, one for `colour_channels`, `height` and `width`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139ded6",
   "metadata": {},
   "source": [
    "### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213afbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninitialized Tensor (5x3):\n",
      " tensor([[6.1663e-33, 1.7698e-42, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a 5x3 matrix, uninitialized\n",
    "x_empty = torch.empty(5, 3)\n",
    "print(\"Uninitialized Tensor (5x3):\\n\", x_empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4813a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Initialized Tensor (5x3):\n",
      " tensor([[0.4775, 0.9785, 0.6593],\n",
      "        [0.7840, 0.5105, 0.0955],\n",
      "        [0.5920, 0.6240, 0.8588],\n",
      "        [0.6076, 0.3772, 0.2686],\n",
      "        [0.8403, 0.2257, 0.5921]])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a randomly initialized matrix\n",
    "x_rand = torch.rand(5, 3)\n",
    "print(\"Randomly Initialized Tensor (5x3):\\n\", x_rand)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25dcef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from data:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor directly from data\n",
    "x_data = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32) # Specify dtype for consistency\n",
    "print(\"Tensor from data:\\n\", x_data)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f38c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor y_rand (5x3):\n",
      " tensor([[0.7757, 0.8902, 0.1962],\n",
      "        [0.3580, 0.3460, 0.1082],\n",
      "        [0.2560, 0.4202, 0.6879],\n",
      "        [0.5671, 0.1826, 0.9218],\n",
      "        [0.1693, 0.4697, 0.4104]])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Operations\n",
    "y_rand = torch.rand(5, 3)\n",
    "print(\"Tensor y_rand (5x3):\\n\", y_rand)\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2e7165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise addition (x_rand + y_rand):\n",
      " tensor([[1.2533, 1.8687, 0.8555],\n",
      "        [1.1420, 0.8566, 0.2037],\n",
      "        [0.8479, 1.0443, 1.5467],\n",
      "        [1.1747, 0.5598, 1.1905],\n",
      "        [1.0096, 0.6954, 1.0025]])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Element-wise addition (x_rand + y_rand):\\n\", x_rand + y_rand)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d512d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 1 (2x3):\n",
      " tensor([[0.2281, 0.2147, 0.7368],\n",
      "        [0.6948, 0.5536, 0.4486]])\n",
      "Matrix 2 (3x2):\n",
      " tensor([[0.5649, 0.0846],\n",
      "        [0.1272, 0.9118],\n",
      "        [0.3729, 0.9616]])\n",
      "Matrix multiplication (mat1 @ mat2):\n",
      " tensor([[0.4308, 0.9235],\n",
      "        [0.6301, 0.9949]])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication requires compatible dimensions\n",
    "mat1 = torch.rand(2, 3)\n",
    "mat2 = torch.rand(3, 2)\n",
    "print(\"Matrix 1 (2x3):\\n\", mat1)\n",
    "print(\"Matrix 2 (3x2):\\n\", mat2)\n",
    "print(\"Matrix multiplication (mat1 @ mat2):\\n\", torch.matmul(mat1, mat2))\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16818864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor z (3x3):\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "Reshaped z to (9,):\n",
      " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "z = torch.arange(9).reshape(3, 3) # Create a 3x3 tensor with values 0-8\n",
    "print(\"Original Tensor z (3x3):\\n\", z)\n",
    "print(\"Reshaped z to (9,):\\n\", z.view(9)) # or z.reshape(9)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dfd6bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row of x_rand: tensor([0.4775, 0.9785, 0.6593])\n",
      "Element at (1, 2) of x_rand: tensor(0.0955)\n",
      "First two rows, all columns of x_rand:\n",
      " tensor([[0.4775, 0.9785, 0.6593],\n",
      "        [0.7840, 0.5105, 0.0955]])\n"
     ]
    }
   ],
   "source": [
    "# Indexing and Slicing\n",
    "print(\"First row of x_rand:\", x_rand[0])\n",
    "print(\"Element at (1, 2) of x_rand:\", x_rand[1, 2])\n",
    "print(\"First two rows, all columns of x_rand:\\n\", x_rand[:2, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458d6754",
   "metadata": {},
   "source": [
    "### Exercise 1: Tensor Manipulation\n",
    "\n",
    "1. Create a 4x4 tensor filled with ones.\n",
    "\n",
    "2. Multiply this tensor by 5.\n",
    "\n",
    "3. Create another 4x4 tensor with random values.\n",
    "\n",
    "4. Perform element-wise multiplication between the two tensors.\n",
    "\n",
    "5. Reshape the resulting tensor into a 1D tensor.\n",
    "\n",
    "6. Print the shape of the final tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d30d1c",
   "metadata": {},
   "source": [
    "## 2. Autograd: Automatic Differentiation\n",
    "This is where PyTorch truly shines for deep learning. The torch.autograd package provides automatic differentiation for all operations on Tensors. This is crucial for training neural networks, as it allows us to compute gradients for backpropagation efficiently.\n",
    "\n",
    "``requires_grad=True:`` If you set **requires_grad=True** for a Tensor, PyTorch will track all operations performed on it. When you finish your computation and call **.backward()** on the resulting scalar, **all gradients will be computed automatically**.\n",
    "\n",
    "``grad attribute:`` The gradients are accumulated into the **.grad** attribute of the Tensor.\n",
    "\n",
    "This automatic differentiation is the backbone of how neural networks learn by adjusting their weights based on the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a5ade",
   "metadata": {},
   "source": [
    "### Autograd in Action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "380cf25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial x: 2.0, requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor and tell PyTorch to track its gradients\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "print(f\"Initial x: {x}, requires_grad: {x.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4274d873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed y: 15.0\n"
     ]
    }
   ],
   "source": [
    "# A simple computation graph: y depends on x\n",
    "y = x**2 + 3*x + 5\n",
    "print(f\"Computed y: {y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c75d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "# y must be a scalar for .backward() without specifying a gradient argument\n",
    "y.backward() # This computes dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "181a5d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of y with respect to x (x.grad): 7.0\n"
     ]
    }
   ],
   "source": [
    "# Access the gradient\n",
    "# dy/dx = 2*x + 3\n",
    "# For x = 2.0, dy/dx = 2*2.0 + 3 = 7.0\n",
    "print(f\"Gradient of y with respect to x (x.grad): {x.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b62eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example with multiple variables\n",
    "a = torch.tensor(3.0, requires_grad=True)\n",
    "b = torch.tensor(4.0, requires_grad=True)\n",
    "c = a * b\n",
    "d = c + a**2\n",
    "d.backward() # Computes gradients for a and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac6363ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient of d with respect to a (a.grad): 10.0\n",
      "Gradient of d with respect to b (b.grad): 3.0\n"
     ]
    }
   ],
   "source": [
    "# d = a*b + a^2\n",
    "# d(d)/d(a) = b + 2*a = 4 + 2*3 = 10\n",
    "# d(d)/d(b) = a = 3\n",
    "print(f\"\\nGradient of d with respect to a (a.grad): {a.grad}\")\n",
    "print(f\"Gradient of d with respect to b (b.grad): {b.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12d62dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor w (created with no_grad): 10.0, requires_grad: False\n"
     ]
    }
   ],
   "source": [
    "# Detaching a tensor from the computation graph\n",
    "# If you don't want to track gradients for certain operations\n",
    "z = torch.tensor(5.0, requires_grad=True)\n",
    "with torch.no_grad(): # Operations inside this context manager will not track gradients\n",
    "    w = z * 2\n",
    "print(f\"\\nTensor w (created with no_grad): {w}, requires_grad: {w.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97357d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor q (detached from p): 10.0, requires_grad: False\n"
     ]
    }
   ],
   "source": [
    "# If you want to detach an existing tensor\n",
    "p = torch.tensor(10.0, requires_grad=True)\n",
    "q = p.detach() # q will be a new tensor that does not require gradients\n",
    "print(f\"Tensor q (detached from p): {q}, requires_grad: {q.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a1262",
   "metadata": {},
   "source": [
    "### Exercise 2: Gradient Calculation\n",
    "\n",
    "1. Define two tensors, $u$ and $v$, both with requires_grad=True. Assign them initial scalar values (e.g., $u=3.0, v=2.0$).\n",
    "\n",
    "2. Define a new tensor $f$ based on u and v using the formula:  $ f=u^3v^2 +5u+2v.$\n",
    "3. Compute the gradients of $f$ with respect to u and v.\n",
    "\n",
    "4. Print the gradients ``u.grad`` and ``v.grad``.\n",
    "\n",
    "5. Manually calculate the expected gradients and verify your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f401add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial u: 3.0, v: 2.0\n",
      "Computed f: 127.0\n",
      "Gradient of f with respect to u (u.grad): 113.0\n",
      "Gradient of f with respect to v (v.grad): 110.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Your code here\n",
    "# 1. Define two tensors, u and v, both with requires_grad=True.\n",
    "u = torch.tensor(3.0, requires_grad=True)\n",
    "v = torch.tensor(2.0, requires_grad=True)\n",
    "print(f\"Initial u: {u}, v: {v}\")\n",
    "\n",
    "# 2. Define a new tensor f based on u and v using the formula: f = u^3 * v^2 + 5u + 2v.\n",
    "f = u**3 * v**2 + 5*u + 2*v\n",
    "print(f\"Computed f: {f}\")\n",
    "\n",
    "# 3. Compute the gradients of f with respect to u and v.\n",
    "f.backward()\n",
    "\n",
    "# 4. Print the gradients u.grad and v.grad.\n",
    "print(f\"Gradient of f with respect to u (u.grad): {u.grad}\")\n",
    "print(f\"Gradient of f with respect to v (v.grad): {v.grad}\")\n",
    "\n",
    "# 5. Manually calculate the expected gradients and verify your results.\n",
    "# f = u^3 * v^2 + 5u + 2v\n",
    "# df/du = 3*u^2 * v^2 + 5\n",
    "# df/dv = u^3 * 2*v + 2\n",
    "\n",
    "# For u=3.0, v=2.0:\n",
    "# df/du = 3*(3.0)^2 * (2.0)^2 + 5 = 3*9*4 + 5 = 108 + 5 = 113\n",
    "# df/dv = (3.0)^3 * 2*(2.0) + 2 = 27 * 4 + 2 = 108 + 2 = 110\n",
    "\n",
    "# The printed gradients should match these manual calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41664f5",
   "metadata": {},
   "source": [
    "### 3. ``nn.Module:`` Building Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbbd7d",
   "metadata": {},
   "source": [
    "The torch.nn module provides all the necessary components for building neural networks. The base class for all neural network modules is torch.nn.Module.\n",
    "\n",
    "Encapsulation: A Module can contain other Modules (e.g., a Sequential module containing Linear and ReLU modules).\n",
    "\n",
    "Parameters: Modules automatically register their learnable parameters (like weights and biases) as nn.Parameters.\n",
    "\n",
    "forward() method: Every nn.Module subclass must override the forward() method. This method defines how the input data flows through the network to produce an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffc4ad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      " SimpleNet(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Model Parameters:\n",
      "  fc1.weight: torch.Size([5, 10])\n",
      "  fc1.bias: torch.Size([5])\n",
      "  fc2.weight: torch.Size([1, 5])\n",
      "  fc2.bias: torch.Size([1])\n",
      "\n",
      "Output shape for dummy input: torch.Size([1, 1])\n",
      "Output for dummy input:\n",
      "tensor([[0.4117]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "Sequential Model Architecture:\n",
      " Sequential(\n",
      "  (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=5, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # Define layers\n",
    "        # Input features=10, output features=5\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        # Input features=5, output features=1\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define forward pass\n",
    "        # Apply ReLU activation after first layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Apply Sigmoid for binary classification output (output between 0 and 1)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "model = SimpleNet()\n",
    "print(\"Model Architecture:\\n\", model)\n",
    "\n",
    "# Print learnable parameters\n",
    "print(\"\\nModel Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"  {name}: {param.shape}\")\n",
    "\n",
    "# Test the forward pass with dummy data\n",
    "dummy_input = torch.randn(1, 10) # Batch size of 1, 10 features\n",
    "output = model(dummy_input)\n",
    "print(f\"\\nOutput shape for dummy input: {output.shape}\")\n",
    "print(f\"Output for dummy input:\\n{output}\")\n",
    "\n",
    "# Example of using nn.Sequential for a simpler network\n",
    "sequential_model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "print(\"\\nSequential Model Architecture:\\n\", sequential_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac841f",
   "metadata": {},
   "source": [
    "### Exercise 3: Building a Multi-Layer Perceptron (MLP)\n",
    "\n",
    "Create an nn.Module class for a simple MLP with the following structure:\n",
    "\n",
    "Input layer with 784 features (e.g., for flattened MNIST images).\n",
    "\n",
    "Hidden layer 1 with 128 neurons, followed by a ReLU activation.\n",
    "\n",
    "Hidden layer 2 with 64 neurons, followed by a ReLU activation.\n",
    "\n",
    "Output layer with 10 neurons (e.g., for 10-class classification), followed by a Softmax activation (use F.log_softmax or nn.Softmax).\n",
    "\n",
    "Instantiate your model and print its architecture. Pass a dummy input of shape (1, 784) through it and print the output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62f1d3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model Architecture:\n",
      " MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Output shape for dummy MLP input: torch.Size([1, 10])\n",
      "Output for dummy MLP input (first 5 values):\n",
      "tensor([-2.2302, -2.1654, -2.2692, -2.4614, -2.4436], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Your code here\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # Input: 784 features\n",
    "        # Hidden Layer 1: 128 neurons, ReLU\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        # Hidden Layer 2: 64 neurons, ReLU\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Output Layer: 10 neurons (for 10 classes)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input if it's not already 1D per sample (e.g., for images)\n",
    "        # x = x.view(x.shape[0], -1) # Uncomment if input is not already flattened\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # For multi-class classification, often use log_softmax for numerical stability with NLLLoss\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MLP\n",
    "mlp_model = MLP()\n",
    "print(\"MLP Model Architecture:\\n\", mlp_model)\n",
    "\n",
    "# Test with dummy input\n",
    "dummy_input_mlp = torch.randn(1, 784) # Batch size of 1, 784 features\n",
    "output_mlp = mlp_model(dummy_input_mlp)\n",
    "print(f\"\\nOutput shape for dummy MLP input: {output_mlp.shape}\")\n",
    "print(f\"Output for dummy MLP input (first 5 values):\\n{output_mlp[0, :5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b9a09",
   "metadata": {},
   "source": [
    "### Building a Simple Neural Network in PyTorch (Conceptual Flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f3f6e",
   "metadata": {},
   "source": [
    "###  the typical steps involved in building and training a deep learning model with PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f68de3",
   "metadata": {},
   "source": [
    "#### Step -1  Data Preparation:\n",
    "\n",
    "- Load your dataset (images, text, tabular data).\n",
    "\n",
    "- Preprocess the data (normalization, tokenization, resizing, etc.).\n",
    "\n",
    "- Split into training, validation, and test sets.\n",
    "\n",
    "- Use torch.utils.data.Dataset and torch.utils.data.DataLoader for efficient data loading and batching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8b673",
   "metadata": {},
   "source": [
    "#### Step - 2 Define the Model:\n",
    "\n",
    "- Create a class that inherits from nn.Module.\n",
    "\n",
    "- In the __init__ method, define the layers of your network (e.g., nn.Linear, nn.Conv2d, nn.ReLU, nn.MaxPool2d).\n",
    "\n",
    "- In the forward method, define the computational flow of data through these layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33420ef6",
   "metadata": {},
   "source": [
    "#### Step -3 Define Loss Function:\n",
    "\n",
    "- Choose an appropriate loss function (also known as criterion) to measure the difference between your model's predictions and the true labels.\n",
    "\n",
    "- Examples: nn.CrossEntropyLoss (for multi-class classification), nn.MSELoss (for regression), nn.BCELoss (for binary classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa82611",
   "metadata": {},
   "source": [
    "#### Step - 4 Define Optimizer:\n",
    "\n",
    "- Choose an optimization algorithm that will update the model's parameters (weights and biases) to minimize the loss.\n",
    "\n",
    "- Examples: torch.optim.SGD (Stochastic Gradient Descent), torch.optim.Adam, torch.optim.RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35234f",
   "metadata": {},
   "source": [
    "#### Step - 5 Training Loop:\n",
    "\n",
    "- Iterate over your dataset for a specified number of epochs.\n",
    "\n",
    "- For each batch:\n",
    "\n",
    "      - Forward Pass: Pass input data through the model to get predictions.\n",
    "\n",
    "      - Calculate Loss: Compute the loss between predictions and true labels.\n",
    "\n",
    "      - Zero Gradients: Clear the gradients from the previous iteration (optimizer.zero_grad()).\n",
    "\n",
    "      - Backward Pass: Compute gradients of the loss with respect to all learnable parameters (loss.backward()).\n",
    "\n",
    "      - Optimizer Step: Update the model's parameters using the computed gradients (optimizer.step()).\n",
    "\n",
    "- Optionally, evaluate the model on the validation set periodically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e3095",
   "metadata": {},
   "source": [
    "#### Step 6 Evaluation:\n",
    "\n",
    "After training, evaluate the model's performance on the unseen test set to get an unbiased estimate of its generalization capability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb22d51",
   "metadata": {},
   "source": [
    "## Key PyTorch Components in Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c813b67",
   "metadata": {},
   "source": [
    "torch.optim: Optimizers\n",
    "\n",
    "The torch.optim package provides various optimization algorithms. These algorithms adjust the model's parameters based on the gradients computed during the backward pass to minimize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8a89cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Optimizer created.\n",
      "Adam Optimizer created.\n",
      "\n",
      "Initial loss: 0.6591\n",
      "Parameters updated after one step.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assume SimpleNet is defined as before\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = SimpleNet()\n",
    "\n",
    "# Example: SGD optimizer\n",
    "# model.parameters() gives the optimizer access to all the learnable parameters of your nn.Module.\n",
    "# lr (learning rate) controls the step size during parameter updates.\n",
    "# momentum (optional) helps accelerate SGD in the relevant direction and dampens oscillations.\n",
    "sgd_optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "print(\"SGD Optimizer created.\")\n",
    "\n",
    "# Example: Adam optimizer\n",
    "# Adam is an adaptive learning rate optimization algorithm.\n",
    "adam_optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(\"Adam Optimizer created.\")\n",
    "\n",
    "# You would typically choose one optimizer for your training.\n",
    "# For demonstration, let's show a conceptual training step:\n",
    "dummy_input = torch.randn(1, 10)\n",
    "dummy_target = torch.tensor([[0.8]], dtype=torch.float32) # Example target for binary classification\n",
    "\n",
    "# 1. Forward pass\n",
    "output = model(dummy_input)\n",
    "\n",
    "# 2. Calculate Loss (using Binary Cross Entropy Loss for sigmoid output)\n",
    "criterion = nn.BCELoss()\n",
    "loss = criterion(output, dummy_target)\n",
    "print(f\"\\nInitial loss: {loss.item():.4f}\")\n",
    "\n",
    "# 3. Zero Gradients\n",
    "# It's crucial to zero the gradients before backpropagation,\n",
    "# otherwise, gradients from previous steps would accumulate.\n",
    "sgd_optimizer.zero_grad()\n",
    "\n",
    "# 4. Backward Pass\n",
    "# This computes d(loss)/d(param) for all parameters that require_grad=True\n",
    "loss.backward()\n",
    "\n",
    "# 5. Optimizer Step\n",
    "# This updates the model's parameters using the calculated gradients\n",
    "# according to the chosen optimization algorithm (e.g., SGD, Adam).\n",
    "sgd_optimizer.step()\n",
    "\n",
    "# After the step, the model's weights and biases have been updated\n",
    "print(\"Parameters updated after one step.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d56e34",
   "metadata": {},
   "source": [
    "## Exercise 4: Experiment with Optimizers\n",
    "\n",
    "- Take the SimpleNet model from the previous section.\n",
    "\n",
    "- Create a dummy dataset (e.g., 100 samples, 10 features, binary labels).\n",
    "\n",
    "- Set up nn.BCELoss as your criterion.\n",
    "\n",
    "- Train the SimpleNet for a few epochs (e.g., 5-10) using torch.optim.SGD with lr=0.01. Print the loss for each epoch.\n",
    "\n",
    "- Reset the model (re-instantiate SimpleNet).\n",
    "\n",
    "- Train the SimpleNet for the same number of epochs using torch.optim.Adam with lr=0.001. Print the loss for each epoch.\n",
    "\n",
    "- Observe and comment on the difference in loss reduction between SGD and Adam (if any) over these few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a4e9fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training with SGD ---\n",
      "Epoch 1/10, SGD Loss: 0.7453\n",
      "Epoch 2/10, SGD Loss: 0.7392\n",
      "Epoch 3/10, SGD Loss: 0.7340\n",
      "Epoch 4/10, SGD Loss: 0.7291\n",
      "Epoch 5/10, SGD Loss: 0.7246\n",
      "Epoch 6/10, SGD Loss: 0.7202\n",
      "Epoch 7/10, SGD Loss: 0.7163\n",
      "Epoch 8/10, SGD Loss: 0.7127\n",
      "Epoch 9/10, SGD Loss: 0.7092\n",
      "Epoch 10/10, SGD Loss: 0.7061\n",
      "\n",
      "--- Training with Adam ---\n",
      "Epoch 1/10, Adam Loss: 0.7981\n",
      "Epoch 2/10, Adam Loss: 0.7903\n",
      "Epoch 3/10, Adam Loss: 0.7835\n",
      "Epoch 4/10, Adam Loss: 0.7769\n",
      "Epoch 5/10, Adam Loss: 0.7707\n",
      "Epoch 6/10, Adam Loss: 0.7653\n",
      "Epoch 7/10, Adam Loss: 0.7607\n",
      "Epoch 8/10, Adam Loss: 0.7560\n",
      "Epoch 9/10, Adam Loss: 0.7524\n",
      "Epoch 10/10, Adam Loss: 0.7474\n",
      "\n",
      "--- Observation ---\n",
      "In this simple example, Adam typically shows faster convergence and a more stable decrease in loss compared to SGD, especially in the initial epochs. SGD might oscillate more but can sometimes reach a better minimum given enough time and proper tuning.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Your code here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Define SimpleNet again for clarity in this exercise block\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# 2. Create a dummy dataset\n",
    "num_samples = 100\n",
    "num_features = 10\n",
    "X_dummy = torch.randn(num_samples, num_features)\n",
    "# Generate binary labels (0 or 1)\n",
    "y_dummy = (torch.rand(num_samples, 1) > 0.5).float()\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "dummy_dataset = TensorDataset(X_dummy, y_dummy)\n",
    "dummy_dataloader = DataLoader(dummy_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 3. Set up nn.BCELoss as your criterion.\n",
    "criterion = nn.BCELoss()\n",
    "num_epochs = 10\n",
    "\n",
    "print(\"--- Training with SGD ---\")\n",
    "# 4. Train with SGD\n",
    "model_sgd = SimpleNet()\n",
    "optimizer_sgd = optim.SGD(model_sgd.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss_sgd = 0\n",
    "    for inputs, targets in dummy_dataloader:\n",
    "        optimizer_sgd.zero_grad()\n",
    "        outputs = model_sgd(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_sgd.step()\n",
    "        total_loss_sgd += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, SGD Loss: {total_loss_sgd / len(dummy_dataloader):.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Training with Adam ---\")\n",
    "# 5. Reset the model (re-instantiate SimpleNet).\n",
    "model_adam = SimpleNet()\n",
    "# 6. Train with Adam\n",
    "optimizer_adam = optim.Adam(model_adam.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss_adam = 0\n",
    "    for inputs, targets in dummy_dataloader:\n",
    "        optimizer_adam.zero_grad()\n",
    "        outputs = model_adam(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_adam.step()\n",
    "        total_loss_adam += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Adam Loss: {total_loss_adam / len(dummy_dataloader):.4f}\")\n",
    "\n",
    "# 7. Observe and comment on the difference in loss reduction.\n",
    "print(\"\\n--- Observation ---\")\n",
    "print(\"In this simple example, Adam typically shows faster convergence and a more stable decrease in loss compared to SGD, especially in the initial epochs. SGD might oscillate more but can sometimes reach a better minimum given enough time and proper tuning.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d699c5",
   "metadata": {},
   "source": [
    "### torch.nn.functional: Functional API for Layers\n",
    "While torch.nn provides module-based layers (which have internal state, like weights), torch.nn.functional provides the functional versions of many operations, often used directly in the forward method of nn.Modules, especially for activation functions, pooling layers, or convolutions that don't have learnable parameters themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d10fdd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunctionalNet Architecture:\n",
      " FunctionalNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Output shape for dummy image input: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FunctionalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FunctionalNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # Learnable parameters here\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # Learnable parameters here\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use F.max_pool2d and F.relu (functional)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320) # Flatten the tensor for the linear layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # Output layer (often no activation here if using CrossEntropyLoss)\n",
    "        return F.log_softmax(x, dim=1) # Use log_softmax for classification output\n",
    "\n",
    "# Create an instance of the network\n",
    "functional_model = FunctionalNet()\n",
    "print(\"FunctionalNet Architecture:\\n\", functional_model)\n",
    "\n",
    "# Test with dummy image data (e.g., 1 channel, 28x28 image)\n",
    "dummy_image_input = torch.randn(1, 1, 28, 28) # Batch size 1, 1 channel, 28x28\n",
    "output_image = functional_model(dummy_image_input)\n",
    "print(f\"\\nOutput shape for dummy image input: {output_image.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5e924",
   "metadata": {},
   "source": [
    "#### torch.utils.data.Dataset and DataLoader: Data Handling\n",
    "\n",
    "These two classes are essential for efficient and organized data loading, especially for large datasets.\n",
    "\n",
    "- Dataset: An abstract class representing a dataset. You typically subclass it and implement:\n",
    "\n",
    "  - __len__: Returns the total number of samples in the dataset.\n",
    "\n",
    "  - __getitem__: Returns a sample from the dataset at a given index.\n",
    "\n",
    "- DataLoader: Wraps a Dataset and provides an iterable over the dataset, supporting:\n",
    "\n",
    "   - Batching: Grouping samples into mini-batches.\n",
    "\n",
    "   - Shuffling: Randomizing the order of samples.\n",
    "\n",
    "   - Multi-process data loading: num_workers for faster data loading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da73ad",
   "metadata": {},
   "source": [
    "### Example Code: Custom Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0558a146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dummy_data: (100, 10)\n",
      "Shape of dummy_labels: (100,)\n",
      "Dataset size: 100 samples\n",
      "First sample from dataset: (tensor([0.0634, 0.2971, 0.9790, 0.5872, 0.7071, 0.3855, 0.8584, 0.3002, 0.7349,\n",
      "        0.1650]), tensor(1))\n",
      "\n",
      "DataLoader created with batch_size=16\n",
      "\n",
      "Iterating through DataLoader (first 2 batches):\n",
      "  Batch 1:\n",
      "    Inputs shape: torch.Size([16, 10])\n",
      "    Targets shape: torch.Size([16])\n",
      "  Batch 2:\n",
      "    Inputs shape: torch.Size([16, 10])\n",
      "    Targets shape: torch.Size([16])\n",
      "\n",
      "DataLoader iteration complete.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. Define a Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        # Convert data and labels to PyTorch tensors\n",
    "        # Use float32 for data (inputs to neural networks)\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        # Use long for classification labels (integers)\n",
    "        # Use float32 for regression labels\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a single sample (data, label) at the given index\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# 2. Prepare Dummy Data\n",
    "# 100 samples, 10 features each\n",
    "dummy_data = np.random.rand(100, 10)\n",
    "# 100 labels, randomly 0 or 1 (binary classification)\n",
    "dummy_labels = np.random.randint(0, 2, 100)\n",
    "\n",
    "print(f\"Shape of dummy_data: {dummy_data.shape}\")\n",
    "print(f\"Shape of dummy_labels: {dummy_labels.shape}\")\n",
    "\n",
    "# 3. Create an instance of your CustomDataset\n",
    "dataset = CustomDataset(dummy_data, dummy_labels)\n",
    "print(f\"Dataset size: {len(dataset)} samples\")\n",
    "print(f\"First sample from dataset: {dataset[0]}\")\n",
    "\n",
    "# 4. Create a DataLoader\n",
    "# batch_size: number of samples per batch\n",
    "# shuffle: True to shuffle data at each epoch (good for training)\n",
    "# num_workers: how many subprocesses to use for data loading (0 means main process)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "print(f\"\\nDataLoader created with batch_size={dataloader.batch_size}\")\n",
    "\n",
    "# 5. Iterate through the dataloader during a conceptual training loop\n",
    "print(\"\\nIterating through DataLoader (first 2 batches):\")\n",
    "for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "    # inputs and targets are now tensors of batch_size\n",
    "    print(f\"  Batch {batch_idx + 1}:\")\n",
    "    print(f\"    Inputs shape: {inputs.shape}\")\n",
    "    print(f\"    Targets shape: {targets.shape}\")\n",
    "    if batch_idx >= 1: # Print only first 2 batches for brevity\n",
    "        break\n",
    "\n",
    "print(\"\\nDataLoader iteration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19337fc",
   "metadata": {},
   "source": [
    "### Exercise 5: Data Loading and Batching\n",
    "\n",
    "- Generate a synthetic dataset: 500 samples, each with 5 features, and corresponding labels (e.g., 0, 1, or 2 for a 3-class problem).\n",
    "\n",
    "- Create a CustomDataset class (similar to the example, but adapt for 5 features and 3 classes).\n",
    "\n",
    "- Create a DataLoader with a batch_size of 32 and shuffle=True.\n",
    "\n",
    "- Iterate through the DataLoader for one full epoch. For each batch, print the batch number, the shape of the inputs, and the shape of the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b4a612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data shape: torch.Size([500, 5])\n",
      "Synthetic labels shape: torch.Size([500])\n",
      "\n",
      "DataLoader created with batch_size=32\n",
      "\n",
      "Iterating through DataLoader for one epoch:\n",
      "  Batch 1:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 2:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 3:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 4:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 5:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 6:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 7:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 8:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 9:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 10:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 11:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 12:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 13:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 14:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 15:\n",
      "    Inputs shape: torch.Size([32, 5])\n",
      "    Targets shape: torch.Size([32])\n",
      "  Batch 16:\n",
      "    Inputs shape: torch.Size([20, 5])\n",
      "    Targets shape: torch.Size([20])\n",
      "\n",
      "Finished iterating through all batches in the epoch.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5: Your code here\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. Generate a synthetic dataset\n",
    "num_samples_ex5 = 500\n",
    "num_features_ex5 = 5\n",
    "num_classes_ex5 = 3\n",
    "\n",
    "X_ex5 = torch.randn(num_samples_ex5, num_features_ex5)\n",
    "y_ex5 = torch.randint(0, num_classes_ex5, (num_samples_ex5,)) # Labels 0, 1, or 2\n",
    "\n",
    "print(f\"Synthetic data shape: {X_ex5.shape}\")\n",
    "print(f\"Synthetic labels shape: {y_ex5.shape}\")\n",
    "\n",
    "# 2. Create a CustomDataset class\n",
    "class ExerciseDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data.float()\n",
    "        self.labels = labels.long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create an instance of the dataset\n",
    "exercise_dataset = ExerciseDataset(X_ex5, y_ex5)\n",
    "\n",
    "# 3. Create a DataLoader\n",
    "batch_size_ex5 = 32\n",
    "exercise_dataloader = DataLoader(exercise_dataset, batch_size=batch_size_ex5, shuffle=True)\n",
    "\n",
    "print(f\"\\nDataLoader created with batch_size={batch_size_ex5}\")\n",
    "\n",
    "# 4. Iterate through the DataLoader for one full epoch\n",
    "print(\"\\nIterating through DataLoader for one epoch:\")\n",
    "for batch_idx, (inputs, targets) in enumerate(exercise_dataloader):\n",
    "    print(f\"  Batch {batch_idx + 1}:\")\n",
    "    print(f\"    Inputs shape: {inputs.shape}\")\n",
    "    print(f\"    Targets shape: {targets.shape}\")\n",
    "\n",
    "print(\"\\nFinished iterating through all batches in the epoch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0728d53",
   "metadata": {},
   "source": [
    "#### Advantages of PyTorch\n",
    "Dynamic Computation Graph: As discussed, this offers flexibility and easier debugging.\n",
    "\n",
    "Pythonic Interface: Feels natural to Python developers, making it quick to pick up.\n",
    "\n",
    "Imperative Programming Style: Operations are executed immediately, which aids in understanding and debugging.\n",
    "\n",
    "Strong Community and Ecosystem: Excellent documentation, tutorials, and a growing number of libraries built on top of PyTorch (e.g., Hugging Face Transformers, PyTorch Lightning).\n",
    "\n",
    "Production Readiness: While often seen as a research framework, PyTorch is increasingly used in production environments, with tools like TorchScript for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fa90344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Scenario 1 ---\n",
      "Path A: x.sum() > 10 was True. Computation graph includes multiplication and addition.\n",
      "Final output z1: tensor([13., 11., 15.], grad_fn=<AddBackward0>)\n",
      "Gradient of z1 w.r.t x1: tensor([2., 2., 2.])\n",
      "\n",
      "--- Running Scenario 2 ---\n",
      "Path B: x.sum() > 10 was False. Computation graph includes squaring and subtraction.\n",
      "Final output z2: tensor([-2.,  1., -2.], grad_fn=<SubBackward0>)\n",
      "Gradient of z2 w.r.t x2: tensor([2., 4., 2.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def dynamic_computation(x):\n",
    "    # This is a standard Python if-else statement.\n",
    "    # The computation graph will be built differently depending on 'x'.\n",
    "    if x.sum() > 10:\n",
    "        # First possible computation path\n",
    "        y = x * 2\n",
    "        z = y + 5\n",
    "        print(\"Path A: x.sum() > 10 was True. Computation graph includes multiplication and addition.\")\n",
    "    else:\n",
    "        # Second possible computation path\n",
    "        y = x**2\n",
    "        z = y - 3\n",
    "        print(\"Path B: x.sum() > 10 was False. Computation graph includes squaring and subtraction.\")\n",
    "\n",
    "    # Now, we compute gradients for the final result 'z'\n",
    "    # The gradients will be specific to the path taken.\n",
    "    z.backward(torch.ones_like(z)) # Pass a gradient to z to start the backward pass\n",
    "    return z, x.grad\n",
    "\n",
    "# --- Scenario 1: Path A is taken ---\n",
    "print(\"--- Running Scenario 1 ---\")\n",
    "x1 = torch.tensor([4.0, 3.0, 5.0], requires_grad=True) # x.sum() = 12 > 10\n",
    "z1, grad1 = dynamic_computation(x1)\n",
    "print(f\"Final output z1: {z1}\")\n",
    "# For Path A, z = (x * 2) + 5\n",
    "# dz/dx = 2\n",
    "print(f\"Gradient of z1 w.r.t x1: {grad1}\\n\") # Expected: tensor([2., 2., 2.])\n",
    "\n",
    "\n",
    "# --- Scenario 2: Path B is taken ---\n",
    "print(\"--- Running Scenario 2 ---\")\n",
    "x2 = torch.tensor([1.0, 2.0, 1.0], requires_grad=True) # x.sum() = 4 < 10\n",
    "z2, grad2 = dynamic_computation(x2)\n",
    "print(f\"Final output z2: {z2}\")\n",
    "# For Path B, z = (x**2) - 3\n",
    "# dz/dx = 2*x\n",
    "print(f\"Gradient of z2 w.r.t x2: {grad2}\\n\") # Expected: tensor([2., 4., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7b69b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dynamic Computation Graph (PyTorch) ---\n",
      "\n",
      "Input Tensor: [4.0, 3.0, 5.0]\n",
      "Path A taken: (input * 2) + 5\n",
      "Intermediate result: [8.0, 6.0, 10.0]\n",
      "Final result: [13.0, 11.0, 15.0]\n",
      "Gradients w.r.t input_tensor: [2.0, 2.0, 2.0]\n",
      "---\n",
      "\n",
      "Input Tensor: [1.0, 2.0, 1.0]\n",
      "Path B taken: (input^2) - 3\n",
      "Intermediate result: [1.0, 4.0, 1.0]\n",
      "Final result: [-2.0, 1.0, -2.0]\n",
      "Gradients w.r.t input_tensor: [2.0, 4.0, 2.0]\n",
      "---\n",
      "\n",
      "--- End of Dynamic Graph Example ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"--- Dynamic Computation Graph (PyTorch) ---\")\n",
    "\n",
    "def perform_dynamic_computation(input_tensor):\n",
    "    # The graph is built step-by-step as these lines execute.\n",
    "    # input_tensor needs requires_grad=True to track operations for gradients.\n",
    "\n",
    "    print(f\"\\nInput Tensor: {input_tensor.tolist()}\")\n",
    "\n",
    "    # Example of dynamic behavior:\n",
    "    # The path taken (and thus the graph structure) depends on the input_tensor's sum.\n",
    "    if input_tensor.sum() > 10:\n",
    "        intermediate_result = input_tensor * 2 # Operation 1: multiplication\n",
    "        final_result = intermediate_result + 5 # Operation 2: addition\n",
    "        print(\"Path A taken: (input * 2) + 5\")\n",
    "    else:\n",
    "        intermediate_result = input_tensor ** 2 # Operation 1: squaring\n",
    "        final_result = intermediate_result - 3 # Operation 2: subtraction\n",
    "        print(\"Path B taken: (input^2) - 3\")\n",
    "\n",
    "    print(f\"Intermediate result: {intermediate_result.tolist()}\")\n",
    "    print(f\"Final result: {final_result.tolist()}\")\n",
    "\n",
    "    # We can perform backward pass immediately after computation\n",
    "    # For a non-scalar output, we need to provide a gradient argument to backward()\n",
    "    # torch.ones_like(final_result) means we want gradients for all elements of final_result\n",
    "    final_result.backward(torch.ones_like(final_result))\n",
    "\n",
    "    # The gradients are now available in input_tensor.grad\n",
    "    print(f\"Gradients w.r.t input_tensor: {input_tensor.grad.tolist()}\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Scenario 1: Input leads to Path A\n",
    "x1 = torch.tensor([4.0, 3.0, 5.0], requires_grad=True) # Sum = 12 > 10\n",
    "perform_dynamic_computation(x1)\n",
    "# Expected gradients for Path A: dz/dx = 2 for each element.\n",
    "\n",
    "# Scenario 2: Input leads to Path B\n",
    "x2 = torch.tensor([1.0, 2.0, 1.0], requires_grad=True) # Sum = 4 < 10\n",
    "perform_dynamic_computation(x2)\n",
    "# Expected gradients for Path B: dz/dx = 2*x for each element.\n",
    "# For x=[1,2,1], gradients should be [2*1, 2*2, 2*1] = [2, 4, 2]\n",
    "\n",
    "print(\"\\n--- End of Dynamic Graph Example ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_ramesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
